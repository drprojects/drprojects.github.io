---
my_name: Damien Robert
title: Efficient 3D Semantic Segmentation with Superpoint Transformer
image: "images/superpoint_transformer/teaser.png"
icon: "images/superpoint_transformer/teaser_mini.png"

to_ign: <a href="https://www.ign.fr">IGN</a>
to_ensg: <a href="https://www.ensg.eu/">ENSG</a>
to_lastig: <a href="https://www.umr-lastig.fr">LASTIG</a>
to_strudel: <a href="https://www.umr-lastig.fr/strudel">STRUDEL</a>
to_acte: <a href="https://www.umr-lastig.fr/acte">ACTE</a>
to_uge:  <a href="https://www.univ-gustave-eiffel.fr">Univ. Gustave Eiffel</a>
to_crigen: <a href="https://www.engie.com/en/innovation-transition-energetique/centres-de-recherche/crigen">ENGIE Lab
    CRIGEN</a>
to_insa_cvl: <a href="">INSA Centre Val-de-Loire Univ de Tours</a>
to_lifat: <a href="https://lifat.univ-tours.fr/">LIFAT</a>
to_ligm: <a href="https://siteigm.univ-mlv.fr/home/">LIGM</a>
to_enpc: <a href="https://ecoledesponts.fr/">Ecole des Ponts</a>

to_loic: <a href="https://loiclandrieu.com/">Lo√Øc Landrieu</a>
to_hugo: <a href="https://1a7r0ch3.github.io/">Hugo Raguet</a>
to_bruno: <a href="https://www.umr-lastig.fr/bruno-vallet/">Bruno Vallet</a>

to_spt_paper: <a href="https://arxiv.org/abs/2306.08045">Paper</a>
to_spt_webpage: <a href="https://drprojects.github.io/superpoint-transformer">Webpage</a>
to_spt_code: <a href="https://github.com/drprojects/superpoint_transformer">Code</a>
to_spt_video: <a href="">Video</a>
to_spt_sota_s3dis: <a
        href="https://paperswithcode.com/sota/semantic-segmentation-on-s3dis?p=efficient-3d-semantic-segmentation-with">S3DIS 6-Fold</a>
to_spt_sota_kitti360: <a
        href="https://paperswithcode.com/sota/3d-semantic-segmentation-on-kitti-360?p=efficient-3d-semantic-segmentation-with">KITTI-360 Val</a>
to_spt_sota_dales: <a
        href="https://paperswithcode.com/sota/3d-semantic-segmentation-on-dales?p=efficient-3d-semantic-segmentation-with">DALES</a>
---
<!-- Imports -->
{% include_relative imports.html %}

<!-- Change colors here -->
<!--<div style="&#45;&#45;color_left:#80cc28;&#45;&#45;color_right:#00aec7">-->
<div style="--color_left:#f2ce02;--color_right:#d46606">

    <!-- Navigation menu -->
    {% include_relative navigation.html %}

    <!-- Header -->
    <section class="page-header">
        <h1 class="project-name">
            {{ page.title }}
        </h1>
<!--        <h2 class="project-tagline">-->
<!--            <img class=profilepicture src={{ page.image }} style="height:15vh; border-radius:0; border: 0;">-->
<!--        </h2>-->
        <h2 class="project-tagline">
            <a href="https://drprojects.github.io/">{{ page.my_name }}</a><sup>1,2</sup>,
            {{ page.to_hugo }}<sup>3</sup>,
            {{ page.to_loic }}<sup>2,4</sup>
        </h2>
        <h2 class="project-tagline">
            <sup>1</sup>CSAI, {{ page.to_crigen }}, France
            <br>
            <sup>2</sup>{{ page.to_lastig }}, {{ page.to_ign }}, {{ page.to_ensg }}, {{ page.to_uge }}, France
            <br>
            <sup>3</sup>{{ page.to_insa_cvl }}, {{ page.to_lifat }}, France
            <br>
            <sup>4</sup>{{ page.to_ligm }}, {{ page.to_enpc }}, {{ page.to_uge }}, France
        </h2>
        <a href=https://github.com/drprojects/superpoint_transformer class="btn">
            <img height="50" src="images/icons/github.svg">Code
        </a>
        <a href=https://arxiv.org/abs/2306.08045 class="btn">
            <img height="50" src="images/icons/paper.svg">Paper
        </a>
<!--        <a href="" class="btn">-->
<!--            <img height="50" src="images/icons/video.svg">Video-->
<!--        </a>-->
    </section>

    <!-- Page content -->
    <section class="main-content">
        <div class="cell border-box-sizing text_cell rendered">
            <div class="inner_cell">
                <div class="text_cell_render border-box-sizing rendered_html">

                    <!-- Abstract -->
                    <h1 id="Abstract">Abstract<a class="anchor-link" href="#Abstract">&#182;</a>
                    </h1>
                    <div class="tom_table">
                        <div class="tom_row">
                            <div class="tom_cell" style="width:40%">
                                <img src="images/superpoint_transformer/teaser.png" alt="superpoint transformer" style="height:30vh;">
                            </div>
                            <div class="tom_cell_text">
                                <p class="blabla">
                                    We introduce a novel <b>superpoint-based transformer</b> ü§ñ architecture for
                                    efficient ‚ö° semantic segmentation of large-scale 3D scenes. Our method incorporates
                                    a fast algorithm to partition point clouds into a
                                    <b>hierarchical superpoint structure üß©</b>,
                                    which makes our preprocessing <b>7 times times faster</b> than existing superpoint-based
                                    approaches. Additionally, we leverage a self-attention mechanism to capture the
                                    relationships between superpoints at multiple scales, leading to <b>state-of-the-art
                                    performance</b> on three challenging benchmark datasets: S3DIS (76.0% mIoU 6-fold),
                                    KITTI360 (63.5% on Val), and DALES (79.6%). With only <b>212k parameters ü¶ã</b>,
                                    our approach is up to <b>200 times more compact</b> than other state-of-the-art models
                                    while maintaining similar performance. Furthermore, our model can be trained on a
                                    <b>single GPU in 3 hours ‚ö°</b> for a fold of the S3DIS dataset, which is
                                    <b>7√ó to 70√ó fewer GPU-hours</b> than the best-performing methods.
                                    Our code and models are accessible at
                                    <a href="https://github.com/drprojects/superpoint_transformer">github.com/drprojects/superpoint_transformer</a>
                                </p>
                            </div>
                        </div>
                    </div>

                    <!-- Interactive visualization -->
                    <h1 id="Motivation">Motivation<a class="anchor-link" href="#Motivation">&#182;</a>
                    </h1>
                    <p class="blabla">
                        This project aims at fusing the best of both worlds: transformers ü§ñ (
                        <a href="https://arxiv.org/abs/2012.09164">Point Transformer</a>,
                        <a href="https://arxiv.org/abs/2203.14508">Stratified Transformer</a>,
                        ...)
                        and superpoint-based approaches üß© (
                        <a href="https://arxiv.org/abs/1711.09869">SPG</a>,
                        <a href="https://arxiv.org/abs/1904.02113">SSP+SPG</a>,
                        ...).
                        <br><br>
                        <dl>
                            <dt>Transformer-based models ü§ñ</dt>
                            <dd>‚úÖ Expressivity</dd>
                            <dd>‚úÖ Capture long-range interactions</dd>
                            <dd>‚ùå Compute effort guided by arbitrary point or voxel samplings</dd>
                            <dd>‚ùå Loads of parameters</dd>
                            <dd>‚ùå Long training</dd>

                            <dt>Superpoint-based models üß©</dt>
                            <dd>‚úÖ Much smaller problem complexity</dd>
                            <dd>‚úÖ Geometry-guided compute effort allocation</dd>
                            <dd>‚úÖ Fast training</dd>
                            <dd>‚úÖ Lightweight model</dd>
                            <dd>‚ùå Long preprocessing time</dd>
                            <dd>‚ùå GNN's expressivity and long-range interactions</dd>
                            <dd>‚ùå No hierarchical reasoning</dd>
                        </dl>
                        <br><br>
                        To this end, we introduce the following:
                        <br><br>
                        <dl>
                            <dt>Superpoint Transformer üß©ü§ñ</dt>
                            <dd>‚úÖ Much smaller problem complexity</dd>
                            <dd>‚úÖ Geometry-guided compute effort allocation</dd>
                            <dd>‚úÖ Fast training</dd>
                            <dd>‚úÖ Lightweight model</dd>
                            <dd>‚ùå ‚û° ‚úÖ Fast parallelized preprocessing</dd>
                            <dd>‚ùå ‚û° ‚úÖ Transformer‚Äôs expressivity and long-range interactions</dd>
                            <dd>‚ùå ‚û° ‚úÖ Multi-scale reasoning on a hierarchical partition üß©</dd>
                        </dl>
                        These changes allow SPT to match -or surpass- the performance of SOTA models
                        with much fewer parameters and in a fraction of their training and inference
                        time. Here are some SPT-facts:
                        <ul>
                            <li>üìä <b>SOTA on S3DIS 6-Fold</b> (76.0 mIoU)</li>
                            <li>üìä <b>SOTA on KITTI-360 Val</b> (63.5 mIoU)</li>
                            <li>üìä <b>Near SOTA on DALES</b> (79.6 mIoU)</li>
                            <li>ü¶ã <b>212k parameters</b> (<a href="https://github.com/guochengqian/PointNeXt">PointNeXt</a> √∑ 200, <a href="https://github.com/dvlab-research/Stratified-Transformer">Stratified Transformer</a> √∑ 40)</li>
                            <li>‚ö° S3DIS training in <b>3 GPU-hours</b> (<a href="https://github.com/guochengqian/PointNeXt">PointNeXt</a> √∑ 7, <a href="https://github.com/dvlab-research/Stratified-Transformer">Stratified Transformer</a> √∑ 70)</li>
                            <li>‚ö° <b>Preprocessing x7 faster than <a href="https://arxiv.org/abs/1711.09869">SPG</a></b></li>
                            <li>Tea</li>
                            <li>Milk</li>
                        </ul>
                    </p>

                    <p class="blabla">
                        The following visualization will help you get a sense of what our
                        hierarchical data structure look like.
                    </p>

                    {% include_relative images/superpoint_transformer/dales_val_power_line.html %}

                    <p class="blabla">
                        Our model architecture replaces
                        <a href="https://arxiv.org/abs/1711.09869">SPG</a>'s
                        Graph Neural Networks with Transformer self-attention blocks, reasoning on a
                        graph connecting ajacent superpoints.
                    </p>
                    <br><br>
                    <div style="text-align: center;">
                        <img src="images/superpoint_transformer/architecture.png" alt="spt architecture" style="height:40vh;">
                    </div>
                    <br><br>
                    <p class="blabla">
                        Visualizing the model size vs performance of 3D semantic segmentation
                        methods on S3DIS 6-Fold, we observe that small, tailored models can offer a
                        more flexible and sustainable alternative to large, generic models for 3D
                        learning.
                        <br><br>
                        <b>With training times of a few hours on a single GPU, SPT
                        allows practitioners to easily customize the models to their specific needs,
                        enhancing the overall usability and accessibility of 3D learning.</b>
                    </p>

                    <div style="text-align: center;">
                        <img src="images/superpoint_transformer/size_vs_perf.png" alt="model size vs performance" style="height:40vh;">
                    </div>
                    
                    <!-- Video -->
<!--                    <h1 id="Video">Video<a class="anchor-link" href="#Video">&#182;</a>-->
<!--                    </h1>-->
<!--                    <div style="text-align: center;">-->
<!--                        <iframe width="800" height="500" src="https://www.youtube.com/embed/SoMKwI863tw"></iframe>-->
<!--                    </div>-->

                    <!-- Resources -->
                    <h1 id="BibTex">BibTex<a class="anchor-link" href="#BibTex">&#182;</a>
                    </h1>
                    <p class="blabla">
                        In case you use all or part of this project, please cite the following paper:
                    </p>
                    <pre>
	                    <code>
@inproceedings{robert2023spt,
  title={Efficient 3D Semantic Segmentation with Superpoint Transformer},
  author={Robert, Damien and Raguet, Hugo and Landrieu, Loic},
  journal={arXiv preprint arXiv:2306.08045},
  year={2023},
url = {\url{https://github.com/drprojects/superpoint_transformer}}

}
	                    </code>
                    </pre>

                    <!-- Acknowledgments -->
                    <h1 id="Acknowledgments">Acknowledgments üôè<a class="anchor-link" href="#Acknowledgments">&#182;</a>
                    </h1>
                    <p class="blabla">
                        This work was funded by {{ page.to_crigen }} and carried out in the {{ page.to_lastig }} research
                        unit of {{ page.to_uge }}. It was supported by ANR project READY3D ANR-19-CE23-0007, and was
                        granted access to the HPC resources of IDRIS under the allocation AD011013388R1 made by GENCI.
                    </p>
                    <p class="blabla">
                        We thank {{ page.to_bruno }},
                        <a href="https://romainloiseau.github.io/">Romain Loiseau</a>,
                        and <a href="https://www.umr-lastig.fr/ewelina-rupnik/">Ewelina Rupnik</a>
                        for inspiring discussions and valuable feedback.
                    </p>

                </div>
            </div>
        </div>

        <!-- Footer -->
        {% include_relative footer.html %}
    </section>

</div>