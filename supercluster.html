---
my_name: Damien Robert
title: Scalable 3D Panoptic Segmentation As Superpoint Graph Clustering
image: "images/supercluster/3dv_2024.png"
icon: "images/supercluster/teaser_mini.png"

to_ign: <a href="https://www.ign.fr">IGN</a>
to_ensg: <a href="https://www.ensg.eu/">ENSG</a>
to_lastig: <a href="https://www.umr-lastig.fr">LASTIG</a>
to_strudel: <a href="https://www.umr-lastig.fr/strudel">STRUDEL</a>
to_acte: <a href="https://www.umr-lastig.fr/acte">ACTE</a>
to_uge:  <a href="https://www.univ-gustave-eiffel.fr">Univ. Gustave Eiffel</a>
to_crigen: <a href="https://www.engie.com/en/innovation-transition-energetique/centres-de-recherche/crigen">ENGIE Lab
    CRIGEN</a>
to_insa_cvl: <a href="">INSA Centre Val-de-Loire Univ de Tours</a>
to_lifat: <a href="https://lifat.univ-tours.fr/">LIFAT</a>
to_ligm: <a href="https://siteigm.univ-mlv.fr/home/">LIGM</a>
to_enpc: <a href="https://ecoledesponts.fr/">Ecole des Ponts</a>

to_loic: <a href="https://loiclandrieu.com/">Lo√Øc Landrieu</a>
to_hugo: <a href="https://1a7r0ch3.github.io/">Hugo Raguet</a>
to_bruno: <a href="https://www.umr-lastig.fr/bruno-vallet/">Bruno Vallet</a>

to_supercluster_paper: <a href="https://arxiv.org/abs/2401.06704">Paper</a>
to_supercluster_webpage: <a href="https://drprojects.github.io/supercluster">Webpage</a>
to_supercluster_code: <a href="https://github.com/drprojects/superpoint_transformer">Code</a>
to_supercluster_video: <a href="">Video</a>
to_supercluster_sota_s3dis: <a
        href="https://paperswithcode.com/sota/panoptic-segmentation-on-s3dis?p=scalable-3d-panoptic-segmentation-with">S3DIS 6-Fold</a>
to_supercluster_sota_s3dis_area5: <a
        href="https://paperswithcode.com/sota/panoptic-segmentation-on-s3dis-area5?p=scalable-3d-panoptic-segmentation-with">S3DIS Area 5</a>
to_supercluster_sota_kitti360: <a
        href="https://paperswithcode.com/sota/panoptic-segmentation-on-kitti-360?p=scalable-3d-panoptic-segmentation-with">KITTI-360 Val</a>
to_supercluster_sota_dales: <a
        href="https://paperswithcode.com/sota/panoptic-segmentation-on-dales?p=scalable-3d-panoptic-segmentation-with">DALES</a>
to_supercluster_sota_scannet: <a
        href="https://paperswithcode.com/sota/panoptic-segmentation-on-scannet?p=scalable-3d-panoptic-segmentation-with">ScanNetV2 Val</a>
---
<!-- Imports -->
{% include_relative imports.html %}

<!-- Change colors here -->
<!--<div style="&#45;&#45;color_left:#80cc28;&#45;&#45;color_right:#00aec7">-->
<div style="--color_left:#f2ce02;--color_right:#d46606">

    <!-- Navigation menu -->
    {% include_relative navigation.html %}

    <!-- Header -->
    <section class="page-header">
        <h1 class="project-name">
            {{ page.title }}
        </h1>
        <h2 class="project-tagline">
            <img class=profilepicture src={{ page.image }} style="height:15vh; border-radius:0; border: 0;">
            <br>
            <b>3DV 2024 Oral üé§</b>
        </h2>
        <h2 class="project-tagline">
            <a href="https://drprojects.github.io/">{{ page.my_name }}</a><sup>1,2</sup>,
            {{ page.to_hugo }}<sup>3</sup>,
            {{ page.to_loic }}<sup>2,4</sup>
        </h2>
        <h2 class="project-tagline">
            <sup>1</sup>CSAI, {{ page.to_crigen }}, France
            <br>
            <sup>2</sup>{{ page.to_lastig }}, {{ page.to_ign }}, {{ page.to_ensg }}, {{ page.to_uge }}, France
            <br>
            <sup>3</sup>{{ page.to_insa_cvl }}, {{ page.to_lifat }}, France
            <br>
            <sup>4</sup>{{ page.to_ligm }}, {{ page.to_enpc }}, {{ page.to_uge }}, France
        </h2>
        <a href=https://github.com/drprojects/superpoint_transformer class="btn">
            <img height="50" src="images/icons/github.svg">Code
        </a>
        <a href=https://arxiv.org/abs/2401.06704 class="btn">
            <img height="50" src="images/icons/paper.svg">Paper
        </a>
<!--        <a href="" class="btn">-->
<!--            <img height="50" src="images/icons/video.svg">Video-->
<!--        </a>-->
    </section>

    <!-- Page content -->
    <section class="main-content">
        <div class="cell border-box-sizing text_cell rendered">
            <div class="inner_cell">
                <div class="text_cell_render border-box-sizing rendered_html">

                    <!-- Abstract -->
                    <h1 id="Abstract">Abstract<a class="anchor-link" href="#Abstract">&#182;</a>
                    </h1>
                    <div class="tom_table">
                        <div class="tom_row">
                            <div class="tom_cell" style="width:40%">
                                <img src="images/supercluster/teaser.png" alt="SuperCluster" style="height:40vh;">
                            </div>
                            <div class="tom_cell_text">
                                <p class="blabla">
                                    We introduce a highly efficient method for <b>panoptic segmentation</b> of large 3D
                                    point clouds by redefining this task as a <b>scalable graph clustering problem</b>.
                                    This approach can be trained using only local auxiliary tasks, thereby eliminating
                                    the resource-intensive instance-matching step during training. Moreover, our
                                    formulation can easily be adapted to the <b>superpoint paradigm üß©</b>, further
                                    increasing its efficiency. This allows our model to process scenes with <b>millions
                                    of points</b> and <b>thousands of objects</b> in a <b>single inferenceon one GPU
                                    ‚ö°</b>. Our method, called <b>SuperCluster</b>, achieves a new state-of-the-art
                                    panoptic segmentation performance for two indoor scanning datasets:
                                    <b>50.1 PQ (+7.8) for S3DIS Area 5</b>, and <b>58.7 PQ (+25.2) for ScanNetV2</b>.
                                    We also set the first state-of-the-art for two large-scale mobile mapping
                                    benchmarks: <b>KITTI-360</b> and <b>DALES</b>. With only <b>209k parameters ü¶ã</b>,
                                    our model is over <b>30 times smaller</b> than the best-competing method and trains
                                    up to <b>15 times faster ‚ö°</b>.
                                    Our code and pretrained models are available at
                                    <a href="https://github.com/drprojects/superpoint_transformer">github.com/drprojects/superpoint_transformer</a>
                                </p>
                            </div>
                        </div>
                    </div>

                    <!-- Interactive visualization -->
                    <h1 id="Motivation">Motivation<a class="anchor-link" href="#Motivation">&#182;</a>
                    </h1>

                    <p class="blabla">
                        Existing panoptic segmentation methods <b>do not scale to large 3D scenes</b> due to several limitations:
                    </p>

                    <div class="tom_table">
                        <div class="tom_row">
                            <div class="tom_cell" style="width:100%">
                                <p class="blabla">
                                    ‚öôÔ∏è Costly matching operation at each training step<br>
                                    üîí Fixed number of predictions<br>
                                    üé≠ Each prediction mask has the size of the scene<br>
                                    üêò Large backbone<br>
                                </p>
                            </div>
                        </div>
                    </div>

                    <p class="blabla">
                        This project proposes a scalable approach for addressing 3D panoptic segmentation.
                        To this end, we formulate panoptic segmentation as the solution of a <b>superpoint graph clustering problem</b>.
<!--                        This work closely builds on our previous Superpoint Transformer paper-->
                    </p>

                    <div class="tom_table">
                        <div class="tom_row">
                            <div class="tom_cell" style="width:45%; margin-left: 10px; margin-right: 10px;">
                                <div style="text-align: center;">
                                    <img src="images/supercluster/motivation_panoptic.png" alt="panoptic segmentation" style="height:35vh;">
                                </div>
                            </div>
                            <div class="tom_cell" style="width:45%; margin-left: 10px; margin-right: 10px;">
                                <div style="text-align: center;">
                                    <img src="images/supercluster/motivation_partition.png" alt="superpoint partition" style="height:35vh;">
                                </div>
                            </div>
                        </div>
                        <div class="tom_row">
                            <div class="tom_cell" style="width:45%; margin-left: 10px; margin-right: 10px; margin-top: 30px;">
                                <p class="blabla" style="text-align: center;">
                                    <b>Panoptic segmentation</b>
                                </p>
                            </div>
                            <div class="tom_cell" style="width:45%; margin-left: 10px; margin-right: 10px; margin-top: 30px;">
                                <p class="blabla" style="text-align: center;">
                                    <b><a href="https://drprojects.github.io/superpoint-transformer">Superpoint partition</a></b>
                                </p>
                            </div>
                        </div>
                    </div>

                    <p class="blabla">
                        Take the above superpoint partition and the desired panoptic segmentation.
                        Instead of learning to classify and assign an instance to each individual
                        point, we propose to learn to group superpoints together.
                    </p>

                    <p class="blabla">
                        Intuitively, we want to group adjacent superpoints together if they are
                        <span style="color: rgb(30, 150, 252)">spatially close</span>, have the
                        <span style="color: rgb(144, 190, 109)">same class</span>, and are
                        <span style="color: rgb(249, 65, 68)">not separated by a border</span>.
                        We translate these goals into the following (superpoint) graph optimization
                        problem.
                    </p>
                    <br>
                    <div style="text-align: center;">
                        <img src="images/supercluster/equation.png" alt="supercluster pipeline and equation" style="height:30vh;">
                    </div>
                    <br>
                    <p class="blabla">
                        Our idea is to train a model to <b>predict the input parameters for
                        this optimization problem</b>, without explicitly asking the model to solve
                        the panoptic segmentation task. If the model does its job, we should <b>only
                        need to solve the graph clustering problem at inference time</b>, circumventing
                        several limitations of existing panoptic segmentation methods.
                    </p>
                    <p class="blabla">
                        Building on our previous
                        <a href="https://drprojects.github.io/superpoint-transformer">Superpoint Transformer</a>
                        work, we already have the building blocks for building a
                        <span style="color: rgb(30, 150, 252)">graph of adjacent superpoints</span>
                        and train a model to
                        <span style="color: rgb(144, 190, 109)">classify</span> them.
                        In this work, we introduce a new head to Superpoint Transformer
                        that learns to predict an <span style="color: rgb(249, 65, 68)">affinity</span>
                        for each edge between two adjacent superpoints, indicating whether they belong
                        to the same instance.
                    </p>
                    <p class="blabla">
                        Interestingly, this <b>SuperCluster</b> model is only trained with <b>local per-node
                        and per-edge objectives</b>. As previously mentioned, we do not need to explicitly
                        compute the panoptic segmentation at training time.
                        This bypasses the need for a matching step between predicted and target instance for
                        computing losses and metrics.
                        At inference time, we use a fast algorithm that finds an approximate solution to
                        the (small) graph optimization problem, yielding the final panoptic segmentation prediction.
                    </p>


                    <h1 id="Results">Results<a class="anchor-link" href="#Results">&#182;</a>
                    </h1>

                    <p class="blabla">
                        SuperCluster achieves <b>state-of-the-art</b> results for 3D panoptic segmentation on
                        large-scale indoor datasets such as <b>S3DIS</b> and <b>ScanNetV2</b>, and sets a first
                        state-of-the-art on large-scale outdoor datasets such as <b>DALES</b> and <b>KITTI-360</b>.
                    </p>

                    <div style="text-align: center;">
                        üìä <b>SOTA on S3DIS 6-Fold</b> (55.9 PQ)
                        <br>
                        üìä <b>SOTA on S3DIS Area 5</b> (50.1 PQ)
                        <br>
                        üìä <b>SOTA on ScanNet Val</b> (58.7 PQ)
                        <br>
                        üìä <b>FIRST on KITTI-360 Val</b> (48.3 PQ)
                        <br>
                        üìä <b>FIRST on DALES</b> (61.2 PQ)
                        <br>
                        ü¶ã <b>212k parameters</b> (<a href="https://github.com/dvlab-research/PointGroup">PointGroup</a> √∑ 37)
                        <br>
                        ‚ö° S3DIS training in <b>4 GPU-hours</b>
                        <br>
                        ‚ö° <b>7.8km¬≤</b> tile of <b>18M</b> points in <b>10.1s</b> on <b>1 GPU</b>
                    </div>

                    <p class="blabla">
                        SuperCluster is capable of processing 3D scenes of unprecedented scale at once on a single
                        GPU.
                    </p>

                    <div style="text-align: center;">
                        <img src="images/supercluster/viz_maxi_s3dis.png" alt="S3DIS inference on one GPU" style="width: 100%;">
                    </div>
                    <h3 id="s3dis_max" style="text-align: center;">S3DIS</h3>
                    <p class="blabla" style="text-align: center;">
                        4.6 floors | 21.3M points | 4565/5298 predicted objects | 7.4 s inference | single 48G GPU
                    </p>
                    <br>
                    <br>

                    <div style="text-align: center;">
                        <img src="images/supercluster/viz_maxi_scannet.png" alt="ScanNetV2 inference on one GPU" style="width: 100%;">
                    </div>
                    <h3 id="scannet_max" style="text-align: center;">ScanNetV2</h3>
                    <p class="blabla" style="text-align: center;">
                        105 scans | 10.9M points | 2148/1683 predicted objects | 6.8 s inference | single 48G GPU
                    </p>
                    <br>
                    <br>

                    <div style="text-align: center;">
                        <img src="images/supercluster/viz_maxi_kitti360_2.png" alt="KITTI-360 inference on one GPU" style="width: 100%;">
                    </div>
                    <h3 id="kitti360_max" style="text-align: center;">KITTI-360</h3>
                    <p class="blabla" style="text-align: center;">
                        7.5 tiles | 11.0M points | 1947/602 predicted objects | 6.6 s inference | single 48G GPU
                    </p>
                    <br>
                    <br>

                    <div style="text-align: center;">
                        <img src="images/supercluster/viz_maxi_dales_2.png" alt="DALES inference on one GPU" style="width: 90%;">
                    </div>
                    <h3 id="dales_max" style="text-align: center;">DALES</h3>
                    <p class="blabla" style="text-align: center;">
                        7.8 km2 | 18.0M points | 1559/1727 predicted objects | 10.1 s inference | single 48G GPU
                    </p>
                    <br>
                    <br>

                    <h1 id="viz">Interactive visualizations<a class="anchor-link" href="#viz">&#182;</a>
                    </h1>

                    {% include_relative images/supercluster/s3dis_panoptic.html %}
                    <h3 id="s3dis_viz" style="text-align: center;">S3DIS</h3>
                    <br>
                    <br>

                    {% include_relative images/supercluster/scannet_panoptic.html %}
                    <h3 id="scannet_viz" style="text-align: center;">ScanNetV2</h3>
                    <br>
                    <br>

                    {% include_relative images/supercluster/dales_panoptic.html %}
                    <h3 id="dales_viz" style="text-align: center;">DALES</h3>
                    <br>
                    <br>

                    {% include_relative images/supercluster/kitti360_panoptic.html %}
                    <h3 id="kitti360_viz" style="text-align: center;">KITTI-360</h3>
                    <br>
                    <br>

                    <!-- Resources -->
                    <h1 id="BibTex">BibTex<a class="anchor-link" href="#BibTex">&#182;</a>
                    </h1>
                    <p class="blabla">
                        In case you use all or part of this project, please cite the following paper:
                    </p>
                    <pre>
	                    <code>
@article{robert2024scalable,
  title={Scalable 3D Panoptic Segmentation as Superpoint Graph Clustering},
  author={Robert, Damien and Raguet, Hugo and Landrieu, Loic},
  journal={Proceedings of the IEEE International Conference on 3D Vision},
  year={2024}
  url = {\url{https://github.com/drprojects/superpoint_transformer}}
}
	                    </code>
                    </pre>

                    <!-- Acknowledgments -->
                    <h1 id="Acknowledgments">Acknowledgments üôè<a class="anchor-link" href="#Acknowledgments">&#182;</a>
                    </h1>
                    <p class="blabla">
                        This work was funded by {{ page.to_crigen }} and carried out in the {{ page.to_lastig }} research
                        unit of {{ page.to_uge }}. It was supported by ANR project READY3D ANR-19-CE23-0007, and was
                        granted access to the HPC resources of IDRIS under the allocation AD011013388R1 made by GENCI.
                    </p>
                </div>
            </div>
        </div>

        <!-- Footer -->
        {% include_relative footer.html %}
    </section>

</div>